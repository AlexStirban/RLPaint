{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Full imports\n",
    "import gym\n",
    "\n",
    "# Aliased imports\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Partial Import\n",
    "from gym.wrappers.monitoring.video_recorder import VideoRecorder\n",
    "from tqdm.notebook import tqdm, trange\n",
    "from IPython.display import clear_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Remember to export to export \"LD_LIBRARY_PATH=$LD_LIBRARY_PATH:$CONDA_PREFIX/lib/\"\" if using linux\n",
    "# Drop numa errors in term: \"for a in /sys/bus/pci/devices/*; do echo 0 | sudo tee -a $a/numa_node; done\"\n",
    "\n",
    "\n",
    "# We have GPU\n",
    "tf.config.list_physical_devices('GPU')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[[0, 0, 0],\n",
       "         [0, 0, 0],\n",
       "         [0, 0, 0],\n",
       "         ...,\n",
       "         [0, 0, 0],\n",
       "         [0, 0, 0],\n",
       "         [0, 0, 0]],\n",
       " \n",
       "        [[0, 0, 0],\n",
       "         [0, 0, 0],\n",
       "         [0, 0, 0],\n",
       "         ...,\n",
       "         [0, 0, 0],\n",
       "         [0, 0, 0],\n",
       "         [0, 0, 0]],\n",
       " \n",
       "        [[0, 0, 0],\n",
       "         [0, 0, 0],\n",
       "         [0, 0, 0],\n",
       "         ...,\n",
       "         [0, 0, 0],\n",
       "         [0, 0, 0],\n",
       "         [0, 0, 0]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[0, 0, 0],\n",
       "         [0, 0, 0],\n",
       "         [0, 0, 0],\n",
       "         ...,\n",
       "         [0, 0, 0],\n",
       "         [0, 0, 0],\n",
       "         [0, 0, 0]],\n",
       " \n",
       "        [[0, 0, 0],\n",
       "         [0, 0, 0],\n",
       "         [0, 0, 0],\n",
       "         ...,\n",
       "         [0, 0, 0],\n",
       "         [0, 0, 0],\n",
       "         [0, 0, 0]],\n",
       " \n",
       "        [[0, 0, 0],\n",
       "         [0, 0, 0],\n",
       "         [0, 0, 0],\n",
       "         ...,\n",
       "         [0, 0, 0],\n",
       "         [0, 0, 0],\n",
       "         [0, 0, 0]]], dtype=uint8),\n",
       " {})"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Def environment\n",
    "env = gym.make(\"CarRacing-v2\", render_mode=\"human\", continuous=False)\n",
    "env.reset()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "for _ in range(30):\n",
    "    env.step(3)\n",
    "    env.render()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on CarRacing in module gym.envs.box2d.car_racing object:\n",
      "\n",
      "class CarRacing(gym.core.Env, gym.utils.ezpickle.EzPickle)\n",
      " |  CarRacing(*args, **kwds)\n",
      " |  \n",
      " |  ### Description\n",
      " |  The easiest control task to learn from pixels - a top-down\n",
      " |  racing environment. The generated track is random every episode.\n",
      " |  \n",
      " |  Some indicators are shown at the bottom of the window along with the\n",
      " |  state RGB buffer. From left to right: true speed, four ABS sensors,\n",
      " |  steering wheel position, and gyroscope.\n",
      " |  To play yourself (it's rather fast for humans), type:\n",
      " |  ```\n",
      " |  python gym/envs/box2d/car_racing.py\n",
      " |  ```\n",
      " |  Remember: it's a powerful rear-wheel drive car - don't press the accelerator\n",
      " |  and turn at the same time.\n",
      " |  \n",
      " |  ### Action Space\n",
      " |  If continuous:\n",
      " |      There are 3 actions: steering (-1 is full left, +1 is full right), gas, and breaking.\n",
      " |  If discrete:\n",
      " |      There are 5 actions: do nothing, steer left, steer right, gas, brake.\n",
      " |  \n",
      " |  ### Observation Space\n",
      " |  State consists of 96x96 pixels.\n",
      " |  \n",
      " |  ### Rewards\n",
      " |  The reward is -0.1 every frame and +1000/N for every track tile visited,\n",
      " |  where N is the total number of tiles visited in the track. For example,\n",
      " |  if you have finished in 732 frames, your reward is\n",
      " |  1000 - 0.1*732 = 926.8 points.\n",
      " |  \n",
      " |  ### Starting State\n",
      " |  The car starts at rest in the center of the road.\n",
      " |  \n",
      " |  ### Episode Termination\n",
      " |  The episode finishes when all of the tiles are visited. The car can also go\n",
      " |  outside of the playfield - that is, far off the track, in which case it will\n",
      " |  receive -100 reward and die.\n",
      " |  \n",
      " |  ### Arguments\n",
      " |  `lap_complete_percent` dictates the percentage of tiles that must be visited by\n",
      " |  the agent before a lap is considered complete.\n",
      " |  \n",
      " |  Passing `domain_randomize=True` enables the domain randomized variant of the environment.\n",
      " |  In this scenario, the background and track colours are different on every reset.\n",
      " |  \n",
      " |  Passing `continuous=False` converts the environment to use discrete action space.\n",
      " |  The discrete action space has 5 actions: [do nothing, left, right, gas, brake].\n",
      " |  \n",
      " |  ### Reset Arguments\n",
      " |  Passing the option `options[\"randomize\"] = True` will change the current colour of the environment on demand.\n",
      " |  Correspondingly, passing the option `options[\"randomize\"] = False` will not change the current colour of the environment.\n",
      " |  `domain_randomize` must be `True` on init for this argument to work.\n",
      " |  Example usage:\n",
      " |  ```py\n",
      " |      env = gym.make(\"CarRacing-v1\", domain_randomize=True)\n",
      " |  \n",
      " |      # normal reset, this changes the colour scheme by default\n",
      " |      env.reset()\n",
      " |  \n",
      " |      # reset with colour scheme change\n",
      " |      env.reset(options={\"randomize\": True})\n",
      " |  \n",
      " |      # reset with no colour scheme change\n",
      " |      env.reset(options={\"randomize\": False})\n",
      " |  ```\n",
      " |  \n",
      " |  ### Version History\n",
      " |  - v1: Change track completion logic and add domain randomization (0.24.0)\n",
      " |  - v0: Original version\n",
      " |  \n",
      " |  ### References\n",
      " |  - Chris Campbell (2014), http://www.iforce2d.net/b2dtut/top-down-car.\n",
      " |  \n",
      " |  ### Credits\n",
      " |  Created by Oleg Klimov\n",
      " |  \n",
      " |  Method resolution order:\n",
      " |      CarRacing\n",
      " |      gym.core.Env\n",
      " |      typing.Generic\n",
      " |      gym.utils.ezpickle.EzPickle\n",
      " |      builtins.object\n",
      " |  \n",
      " |  Methods defined here:\n",
      " |  \n",
      " |  __init__(self, render_mode: Union[str, NoneType] = None, verbose: bool = False, lap_complete_percent: float = 0.95, domain_randomize: bool = False, continuous: bool = True)\n",
      " |      Initialize self.  See help(type(self)) for accurate signature.\n",
      " |  \n",
      " |  close(self)\n",
      " |      Override close in your subclass to perform any necessary cleanup.\n",
      " |      \n",
      " |      Environments will automatically :meth:`close()` themselves when\n",
      " |      garbage collected or when the program exits.\n",
      " |  \n",
      " |  render(self)\n",
      " |      Compute the render frames as specified by render_mode attribute during initialization of the environment.\n",
      " |      \n",
      " |      The set of supported modes varies per environment. (And some\n",
      " |      third-party environments may not support rendering at all.)\n",
      " |      By convention, if render_mode is:\n",
      " |      \n",
      " |      - None (default): no render is computed.\n",
      " |      - human: render return None.\n",
      " |        The environment is continuously rendered in the current display or terminal. Usually for human consumption.\n",
      " |      - rgb_array: return a single frame representing the current state of the environment.\n",
      " |        A frame is a numpy.ndarray with shape (x, y, 3) representing RGB values for an x-by-y pixel image.\n",
      " |      - rgb_array_list: return a list of frames representing the states of the environment since the last reset.\n",
      " |        Each frame is a numpy.ndarray with shape (x, y, 3), as with `rgb_array`.\n",
      " |      - ansi: Return a strings (str) or StringIO.StringIO containing a\n",
      " |        terminal-style text representation for each time step.\n",
      " |        The text can include newlines and ANSI escape sequences (e.g. for colors).\n",
      " |      \n",
      " |      Note:\n",
      " |          Make sure that your class's metadata 'render_modes' key includes\n",
      " |          the list of supported modes. It's recommended to call super()\n",
      " |          in implementations to use the functionality of this method.\n",
      " |  \n",
      " |  reset(self, *, seed: Union[int, NoneType] = None, options: Union[dict, NoneType] = None)\n",
      " |      Resets the environment to an initial state and returns the initial observation.\n",
      " |      \n",
      " |      This method can reset the environment's random number generator(s) if ``seed`` is an integer or\n",
      " |      if the environment has not yet initialized a random number generator.\n",
      " |      If the environment already has a random number generator and :meth:`reset` is called with ``seed=None``,\n",
      " |      the RNG should not be reset. Moreover, :meth:`reset` should (in the typical use case) be called with an\n",
      " |      integer seed right after initialization and then never again.\n",
      " |      \n",
      " |      Args:\n",
      " |          seed (optional int): The seed that is used to initialize the environment's PRNG.\n",
      " |              If the environment does not already have a PRNG and ``seed=None`` (the default option) is passed,\n",
      " |              a seed will be chosen from some source of entropy (e.g. timestamp or /dev/urandom).\n",
      " |              However, if the environment already has a PRNG and ``seed=None`` is passed, the PRNG will *not* be reset.\n",
      " |              If you pass an integer, the PRNG will be reset even if it already exists.\n",
      " |              Usually, you want to pass an integer *right after the environment has been initialized and then never again*.\n",
      " |              Please refer to the minimal example above to see this paradigm in action.\n",
      " |          options (optional dict): Additional information to specify how the environment is reset (optional,\n",
      " |              depending on the specific environment)\n",
      " |      \n",
      " |      \n",
      " |      Returns:\n",
      " |          observation (object): Observation of the initial state. This will be an element of :attr:`observation_space`\n",
      " |              (typically a numpy array) and is analogous to the observation returned by :meth:`step`.\n",
      " |          info (dictionary):  This dictionary contains auxiliary information complementing ``observation``. It should be analogous to\n",
      " |              the ``info`` returned by :meth:`step`.\n",
      " |  \n",
      " |  step(self, action: Union[numpy.ndarray, int])\n",
      " |      Run one timestep of the environment's dynamics.\n",
      " |      \n",
      " |      When end of episode is reached, you are responsible for calling :meth:`reset` to reset this environment's state.\n",
      " |      Accepts an action and returns either a tuple `(observation, reward, terminated, truncated, info)`.\n",
      " |      \n",
      " |      Args:\n",
      " |          action (ActType): an action provided by the agent\n",
      " |      \n",
      " |      Returns:\n",
      " |          observation (object): this will be an element of the environment's :attr:`observation_space`.\n",
      " |              This may, for instance, be a numpy array containing the positions and velocities of certain objects.\n",
      " |          reward (float): The amount of reward returned as a result of taking the action.\n",
      " |          terminated (bool): whether a `terminal state` (as defined under the MDP of the task) is reached.\n",
      " |              In this case further step() calls could return undefined results.\n",
      " |          truncated (bool): whether a truncation condition outside the scope of the MDP is satisfied.\n",
      " |              Typically a timelimit, but could also be used to indicate agent physically going out of bounds.\n",
      " |              Can be used to end the episode prematurely before a `terminal state` is reached.\n",
      " |          info (dictionary): `info` contains auxiliary diagnostic information (helpful for debugging, learning, and logging).\n",
      " |              This might, for instance, contain: metrics that describe the agent's performance state, variables that are\n",
      " |              hidden from observations, or individual reward terms that are combined to produce the total reward.\n",
      " |              It also can contain information that distinguishes truncation and termination, however this is deprecated in favour\n",
      " |              of returning two booleans, and will be removed in a future version.\n",
      " |      \n",
      " |          (deprecated)\n",
      " |          done (bool): A boolean value for if the episode has ended, in which case further :meth:`step` calls will return undefined results.\n",
      " |              A done signal may be emitted for different reasons: Maybe the task underlying the environment was solved successfully,\n",
      " |              a certain timelimit was exceeded, or the physics simulation has entered an invalid state.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data and other attributes defined here:\n",
      " |  \n",
      " |  __parameters__ = ()\n",
      " |  \n",
      " |  metadata = {'render_fps': 50, 'render_modes': ['human', 'rgb_array', '...\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from gym.core.Env:\n",
      " |  \n",
      " |  __enter__(self)\n",
      " |      Support with-statement for the environment.\n",
      " |  \n",
      " |  __exit__(self, *args)\n",
      " |      Support with-statement for the environment.\n",
      " |  \n",
      " |  __str__(self)\n",
      " |      Returns a string of the environment with the spec id if specified.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Readonly properties inherited from gym.core.Env:\n",
      " |  \n",
      " |  unwrapped\n",
      " |      Returns the base non-wrapped environment.\n",
      " |      \n",
      " |      Returns:\n",
      " |          Env: The base non-wrapped gym.Env instance\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data descriptors inherited from gym.core.Env:\n",
      " |  \n",
      " |  __dict__\n",
      " |      dictionary for instance variables (if defined)\n",
      " |  \n",
      " |  __weakref__\n",
      " |      list of weak references to the object (if defined)\n",
      " |  \n",
      " |  np_random\n",
      " |      Returns the environment's internal :attr:`_np_random` that if not set will initialise with a random seed.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data and other attributes inherited from gym.core.Env:\n",
      " |  \n",
      " |  __annotations__ = {'_np_random': typing.Union[numpy.random._generator....\n",
      " |  \n",
      " |  __orig_bases__ = (typing.Generic[~ObsType, ~ActType],)\n",
      " |  \n",
      " |  render_mode = None\n",
      " |  \n",
      " |  reward_range = (-inf, inf)\n",
      " |  \n",
      " |  spec = None\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Class methods inherited from typing.Generic:\n",
      " |  \n",
      " |  __class_getitem__(params) from builtins.type\n",
      " |  \n",
      " |  __init_subclass__(*args, **kwargs) from builtins.type\n",
      " |      This method is called when a class is subclassed.\n",
      " |      \n",
      " |      The default implementation does nothing. It may be\n",
      " |      overridden to extend subclasses.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Static methods inherited from typing.Generic:\n",
      " |  \n",
      " |  __new__(cls, *args, **kwds)\n",
      " |      Create and return a new object.  See help(type) for accurate signature.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from gym.utils.ezpickle.EzPickle:\n",
      " |  \n",
      " |  __getstate__(self)\n",
      " |      Returns the object pickle state with args and kwargs.\n",
      " |  \n",
      " |  __setstate__(self, d)\n",
      " |      Sets the object pickle state using d.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(env.unwrapped)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.13 ('rlenv')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "4bc5bdd1f96b0bfe1b0a7578d394c815a18b7bbf3d83f21c57372441a2e86538"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
